# Radio2Note 仕様書

---

## サービス概要

ラジオ番組にゲスト出演するような対話体験を通じて、ユーザーの一次情報をnote記事として成型するサービス。

### コンセプト

- ユーザーは「受け側のゲスト」
- 話術に長けたMC役AIが、ユーザーの中に眠った面白い話の種を引き出す
- 対話内容が記事として整形され、ユーザーはそれをSNSやnoteに投稿する

### ターゲットユーザー

- Xやnoteで記事を書きたいが、文章を書くのが苦手
- 深夜ラジオが好き
- Podcast配信に憧れはあるが、話術に自信がない

---

## 基本フロー

### 1. 収録前

- トークテーマを入力（必須）
- 一言メモを入力（任意、MCに拾ってほしいポイント）

### 2. 収録中（対話）

以下の4ステップで進行する。

1. **テーマ発表** … 今日は何について話すか
2. **きっかけ** … なぜそれを始めた・出会った
3. **わかったこと** … やってみての発見・学び
4. **まとめ** … 振り返り・これから始める人へ

### 3. 収録後

- 記事のトーン選択（一人称 / 三人称）
- 記事生成
- ユーザーがテキストをコピーし、任意のプラットフォームに投稿

---

## 記事仕様

- 文字数：3,000〜5,000字（note記事1本分）
- 対話時間目安：15〜30分
- 構成：AIが編集し、導入・本題・締めの構造に整形

---

## MC役AI

- 複数のMCキャラクターから選択可能（MVP後に追加）
- 話術のスタイルを参考に設計（間の取り方、相槌パターン、質問の入り方など）
- 声の再現や声色の模倣は行わない
- 音声合成は「ラジオMCっぽい落ち着いたトーン」を採用

---

## 音声データの扱い

- 音声は記事生成のための素材
- 保存・公開機能はMVPでは実装しない
- 必要であればユーザーが手動でダウンロードし、外部サービスで公開

---

## データ設計

### 音声データの構造化

対話音声は以下の要素をJSON形式で保持する。

- **話者識別** … MC / ユーザーの発言を区別
- **タイムスタンプ** … 各発言の開始・終了時刻
- **段落分け** … 意味のまとまりごとに区切り
- **ステップタグ** … 4ステップ（テーマ発表/きっかけ/わかったこと/まとめ）のどこに該当するか
- **ハイライト** … 記事化に有用な発言のフラグ

### 構造化のメリット

- 記事生成時に「この部分をリードに」「ここをオチに」といった編集が容易
- 将来的なコーナー機能追加時に拡張しやすい
- 記事トーンのバリエーション展開に対応可能

---

## 技術スタック

### LLMの使い分け

| 処理 | 使用モデル |
|------|-----------|
| 音声→テキスト | Whisper API（またはfaster-whisper） |
| 話者分離 | pyannote.audio |
| 対話（MC役） | Claude API |
| 記事生成・構成編集 | Claude API |

### 参考アーキテクチャ

AWS Step Functions + Lambdaによるサーバーレス構成を参考にする。

参考記事：「$1で最大8時間の動画を話者分離・文字起こし・LLM分析するAWSパイプラインを作った」

#### 処理フロー

```
[音声入力]
    │
    ▼
┌─────────────────────────────────────────────────────┐
│ 1. 音声抽出（ffmpeg）                                │
│    → 16kHz モノラル WAV                             │
└─────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────┐
│ 2. チャンク分割（必要に応じて）                       │
│    → 8分 + 30秒オーバーラップ                        │
│    → 15〜30分の対話なら分割不要の可能性あり          │
└─────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────┐
│ 3. 話者分離（pyannote.audio）                        │
│    → MC / ユーザーの発言を識別                       │
│    → 埋め込みベクトルで話者統一                      │
└─────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────┐
│ 4. 文字起こし（faster-whisper）                      │
│    → 話者ごとにセグメント化されたテキスト            │
│    → タイムスタンプ付き                             │
└─────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────┐
│ 5. 構造化（Claude API）                              │
│    → ステップタグ付与                               │
│    → ハイライト抽出                                 │
│    → JSON出力                                       │
└─────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────┐
│ 6. 記事生成（Claude API）                            │
│    → トーン選択に応じた文体                         │
│    → 構成編集（導入・本題・締め）                    │
└─────────────────────────────────────────────────────┘
```

#### 技術選定の理由

| 技術 | 選定理由 |
|------|----------|
| pyannote.audio | 話者分離精度が高い、Hugging Face統合 |
| faster-whisper | Whisperの4-8倍高速、int8量子化対応 |
| Claude API | 対話生成・記事編集の品質 |
| AWS Lambda | サーバーレスで従量課金、固定費最小化 |
| Step Functions | ワークフロー管理、エラーハンドリング |

#### コスト見積もり（15〜30分の対話）

| 処理 | 推定コスト |
|------|-----------|
| 話者分離 + 文字起こし | $0.05〜0.10 |
| Claude API（対話 + 記事生成） | $0.10〜0.30 |
| 音声合成（MC役） | $0.05〜0.10 |
| **合計** | **$0.20〜0.50 / 収録** |

### MVP構成

- フロント：最小構成（Webアプリ、バイブコーディング）
- 音声入力：Whisper API または faster-whisper
- 話者分離：pyannote.audio
- 対話・記事生成：Claude API
- 音声合成：OpenAI TTS または VOICEVOX
- データ形式：JSON構造化

### MVPで実装しないもの

- コーナー選択機能
- 音声保存・公開機能
- 外部サービス連携（投稿API等）
- 複数MCキャラクター（MVP後に追加）
- AWSサーバーレス構成（MVPはローカル or シンプルなサーバーで検証）

---

## 今後の拡張案

- コーナー機能（コーナーを組み合わせて番組構成をカスタマイズ）
- 季節限定コーナー、お題ガチャコーナー
- 音声ダウンロード機能
- 記事トーンのバリエーション追加（エッセイ風、インタビュー記事風など）
- 記事テンプレートの拡充
- 初心者向けおすすめセット
- LINEミニアプリ対応
- AWSサーバーレス構成への移行（スケール時）
